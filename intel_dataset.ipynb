{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac8b914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "import pathlib\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c0e640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['street', 'forest', 'sea', 'glacier', 'mountain', 'buildings']\n"
     ]
    }
   ],
   "source": [
    "train_dir = './intel/seg_train/seg_train'\n",
    "valid_dir = './intel/seg_test/seg_test'\n",
    "outcomes = os.listdir(train_dir)\n",
    "print(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916bbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                          transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "validing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                              [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495eb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageFloder function uses for make dataset by passing dir adderess as an argument\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_dir,transform=training_transforms)\n",
    "valid_data = torchvision.datasets.ImageFolder(root=valid_dir,transform=validing_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c2f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.15\n",
    "# Splot data into train and validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7129be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=32,sampler=train_sampler,num_workers=2)\n",
    "valid_loader = DataLoader(train_data, batch_size =32, sampler=valid_sampler, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b1e4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afc91877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "985526b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet_18(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet_18(3, 6)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The model will be running on\", device, \"device\")\n",
    "# Convert model parameters and buffers to CPU or Cuda\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c890e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show the images\n",
    "def imageshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to test the model with a batch of images and show the labels predictions\n",
    "def testBatch():\n",
    "    # get batch of images from the test DataLoader  \n",
    "    images, labels = next(iter(test_loader))\n",
    "\n",
    "    # show all images as one image grid\n",
    "    imageshow(torchvision.utils.make_grid(images))\n",
    "   \n",
    "    # Show the real labels on the screen \n",
    "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
    "                               for j in range(batch_size)))\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca7975d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./ResNet18+intel.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45327d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 1 the test accuracy over the whole test set is 60 %\n",
      "time : 17.54665446281433\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    num_epochs = 1\n",
    "    best_accuracy = 0.0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            \n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            \n",
    "            #將梯度初始化为零\n",
    "            optimizer.zero_grad()\n",
    "            # 向前傳播求出預測的值\n",
    "            outputs = model(images)\n",
    "            # 用output和label計算loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "            # 更新參數\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            path = \"./ResNet18+intel.pth\"\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_accuracy = accuracy\n",
    "        end = time.time()\n",
    "        print(f\"time : {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ffb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
