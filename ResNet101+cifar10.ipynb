{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9f7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f739b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "The number of images in a training set is:  50000\n",
      "Files already downloaded and verified\n",
      "The number of images in a test set is:  10000\n",
      "The number of batches per epoch is:  5000\n"
     ]
    }
   ],
   "source": [
    "# Loading and normalizing the data.\n",
    "# Define transformations for the training and test sets\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# CIFAR10 dataset consists of 50K training images. We define the batch size of 10 to load 5,000 batches of images.\n",
    "batch_size = 10\n",
    "number_of_labels = 10 \n",
    "\n",
    "# Create an instance for training. \n",
    "# When we run this code for the first time, the CIFAR10 train dataset will be downloaded locally. \n",
    "train_set =CIFAR10(root=\"./data\",train=True,transform=transformations,download=True)\n",
    "\n",
    "# Create a loader for the training set which will read the data within batch size and put into memory.\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)\n",
    "\n",
    "# Create an instance for testing, note that train is set to False.\n",
    "# When we run this code for the first time, the CIFAR10 test dataset will be downloaded locally. \n",
    "test_set = CIFAR10(root=\"./data\", train=False, transform=transformations, download=True)\n",
    "\n",
    "# Create a loader for the test set which will read the data within batch size and put into memory. \n",
    "# Note that each shuffle is set to false for the test loader.\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
    "\n",
    "print(\"The number of batches per epoch is: \", len(train_loader))\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eeeb47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01f493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, block_dim):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = block_dim*4\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(input_dim,block_dim,1,bias=False),\n",
    "            nn.Conv2d(block_dim,block_dim,3,padding=1,bias=False),\n",
    "            nn.Conv2d(block_dim,self.output_dim,1,bias=False)\n",
    "        )\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, self.output_dim, 1,bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tmp = self.block(x)\n",
    "        if self.input_dim != self.output_dim:\n",
    "            res = self.downsample(x)\n",
    "        else:\n",
    "            res = x\n",
    "        tmp = tmp + res\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e210c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet101(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet101, self).__init__()\n",
    "        self.foot = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,stride=2, padding = 3),\n",
    "            nn.MaxPool2d(3,stride=2)\n",
    "        )\n",
    "        self.block1 = nn.Sequential(\n",
    "            ConvBlock(64,64),  #(64,64) => (64,64) => (64,256)\n",
    "            ConvBlock(256,64), #(256,64) => (64,64) => (64,256) \n",
    "            ConvBlock(256,64)  #(256,64) => (64,64) => (64,256)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            ConvBlock(256,128), #(256,128) => (128,128) => (128,512)\n",
    "            ConvBlock(512,128), #(512,128) => (128,128) => (128,512)\n",
    "            ConvBlock(512,128), #(512,128) => (128,128) => (128,512)\n",
    "            ConvBlock(512,128), #(512,128) => (128,128) => (128,512)\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            ConvBlock(512,256), #(512,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            ConvBlock(1024,256),#(1024,256) => (256,256) => (256,1024)\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            ConvBlock(1024,512),#(1024,512) => (512,512) => (512,2048)\n",
    "            ConvBlock(2048,512),#(2048,512) => (512,512) => (512,2048)\n",
    "            ConvBlock(2048,512),#(2048,512) => (512,512) => (512,2048)\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        tmp = self.foot(x)\n",
    "        tmp = self.block1(tmp)\n",
    "        tmp = self.block2(tmp)\n",
    "        tmp = self.block3(tmp)\n",
    "        tmp = self.block4(tmp)\n",
    "        tmp = torch.flatten(tmp,start_dim=1)\n",
    "        tmp = self.fc(tmp)\n",
    "\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34edd17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./ResNet101.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea5d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to show the images\n",
    "def imageshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to test the model with a batch of images and show the labels predictions\n",
    "def testBatch():\n",
    "    # get batch of images from the test DataLoader  \n",
    "    images, labels = next(iter(test_loader))\n",
    "\n",
    "    # show all images as one image grid\n",
    "    imageshow(torchvision.utils.make_grid(images))\n",
    "   \n",
    "    # Show the real labels on the screen \n",
    "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
    "                               for j in range(batch_size)))\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5390a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 37246426167686602752.000\n",
      "[1,  2000] loss: 236850112011173.875\n",
      "[1,  3000] loss: 96138099779698.688\n",
      "[1,  4000] loss: 59416800632242.180\n",
      "[1,  5000] loss: 69643945892380.672\n",
      "For epoch 1 the test accuracy over the whole test set is 7 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = ResNet101().to(device)\n",
    "    num_epochs = 1\n",
    "    best_accuracy = 0.0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            \n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            \n",
    "            #將梯度初始化为零\n",
    "            optimizer.zero_grad()\n",
    "            # 向前傳播求出預測的值\n",
    "            outputs = model(images)\n",
    "            # 用output和label計算loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "            # 更新參數\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            path = \"./ResNet101_weight.pth\"\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6923f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
